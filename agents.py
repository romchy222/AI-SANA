import logging
import time
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

from mistral_client import MistralClient

logger = logging.getLogger(__name__)

class AgentType:
    AI_ABITUR = "ai_abitur"
    KADRAI = "kadrai"
    UNINAV = "uninav"
    CAREER_NAVIGATOR = "career_navigator"
    UNIROOM = "uniroom"

class BaseAgent(ABC):
    def __init__(self, agent_type: str, name: str, description: str):
        self.agent_type = agent_type
        self.name = name
        self.description = description
        # Each agent has its own MistralClient instance
        self.mistral = MistralClient()

    @abstractmethod
    def can_handle(self, message: str, language: str = "ru") -> float:
        pass

    @abstractmethod
    def get_system_prompt(self, language: str = "ru") -> str:
        pass

    def process_message(self, message: str, language: str = "ru", user_id: str = "anonymous") -> Dict[str, Any]:
        try:
            start_time = time.time()
            
            # Import advanced components
            from analytics_engine import analytics_engine
            from personalization_engine import personalization_engine
            from distributed_system import performance_optimizer
            
            # Check performance optimization first
            optimization_result = performance_optimizer.optimize_response_generation(
                message, self.agent_type, language
            )
            
            if optimization_result.get('cached'):
                # Track cached interaction
                interaction_data = {
                    'user_id': user_id,
                    'message': message,
                    'agent_type': self.agent_type,
                    'agent_name': self.name,
                    'confidence': optimization_result['response'].get('confidence', 1.0),
                    'response_time': optimization_result['optimization_time'],
                    'cached': True,
                    'context_used': True,
                    'context_confidence': 1.0,
                    'language': language
                }
                analytics_engine.track_interaction(interaction_data)
                
                return {
                    **optimization_result['response'],
                    'cached': True,
                    'optimization_time': optimization_result['optimization_time']
                }
            
            # Check if async processing is recommended
            if optimization_result.get('async_processing'):
                return {
                    'response': optimization_result['message'],
                    'confidence': 0.8,
                    'agent_type': self.agent_type,
                    'agent_name': self.name,
                    'cached': False,
                    'async_processing': True
                }
            
            # Check cache first for performance
            from response_cache import response_cache
            
            cached_response = response_cache.get(message, self.agent_type, language)
            if cached_response:
                # Update user personalization
                personalization_engine.update_user_interaction(user_id, {
                    'message': message,
                    'agent_type': self.agent_type,
                    'confidence': cached_response.get('confidence', 1.0),
                    'cached': True,
                    'language': language
                })
                
                logger.info(f"Returning cached response for {self.name}")
                return {
                    **cached_response,
                    'cached': True
                }
            
            # Get agent-specific system prompt
            system_prompt = self.get_system_prompt(language)
            
            # Get agent-specific context from knowledge base with semantic search
            context = self.get_agent_context(message, language)
            
            # Calculate context confidence for overall response confidence
            context_confidence = self._assess_context_confidence(context, message)
            
            # Use agent-specific system prompt for this message
            response = self.mistral.get_response_with_system_prompt(
                message, context, language, system_prompt
            )
            
            # Apply personalization to response
            personalized_response = personalization_engine.adapt_response_style(user_id, response)
            
            # Calculate overall confidence based on agent matching and context quality
            base_confidence = self.can_handle(message, language)
            overall_confidence = self._calculate_overall_confidence(
                base_confidence, context_confidence, bool(context)
            )
            
            # Calculate response time
            response_time = time.time() - start_time
            
            response_data = {
                'response': personalized_response,
                'confidence': overall_confidence,
                'agent_type': self.agent_type,
                'agent_name': self.name,
                'context_used': bool(context),
                'context_confidence': context_confidence,
                'cached': False,
                'response_time': response_time,
                'user_id': user_id
            }
            
            # Generate proactive suggestions
            suggestions = personalization_engine.generate_proactive_suggestions(user_id, context)
            if suggestions:
                response_data['suggestions'] = suggestions
            
            # Update user personalization
            personalization_engine.update_user_interaction(user_id, {
                'message': message,
                'agent_type': self.agent_type,
                'agent_name': self.name,
                'confidence': overall_confidence,
                'response_time': response_time,
                'context_used': bool(context),
                'context_confidence': context_confidence,
                'language': language
            })
            
            # Track interaction in analytics
            analytics_engine.track_interaction({
                'user_id': user_id,
                'message': message,
                'agent_type': self.agent_type,
                'agent_name': self.name,
                'confidence': overall_confidence,
                'response_time': response_time,
                'cached': False,
                'context_used': bool(context),
                'context_confidence': context_confidence,
                'language': language
            })
            
            # Cache successful responses
            if response_cache.should_cache(message, response_data):
                response_cache.set(message, self.agent_type, response_data, language)
                
            return response_data
            
        except Exception as e:
            logger.error(f"Error in {self.name} agent: {str(e)}")
            
            # Track error
            try:
                from analytics_engine import analytics_engine
                analytics_engine.track_error({
                    'error_type': 'agent_processing_error',
                    'agent_type': self.agent_type,
                    'message': message,
                    'error_details': str(e),
                    'user_impact': 'response_fallback'
                })
            except:
                pass  # Don't let analytics errors break the response
            
            return {
                'response': f"Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ '{self.description}'.",
                'confidence': 0.1,
                'agent_type': self.agent_type,
                'agent_name': self.name,
                'context_used': False,
                'context_confidence': 0.0,
                'cached': False,
                'error': True
            }
    
    def _assess_context_confidence(self, context: str, message: str) -> float:
        """Assess confidence in the retrieved context"""
        if not context:
            return 0.0
            
        # Simple heuristics for context confidence
        message_words = set(message.lower().split())
        context_words = set(context.lower().split())
        
        # Word overlap ratio
        if message_words:
            overlap = len(message_words.intersection(context_words))
            word_confidence = overlap / len(message_words)
        else:
            word_confidence = 0.0
            
        # Context length confidence (more content usually means better info)
        length_confidence = min(1.0, len(context) / 1000)  # Normalize to 1000 chars
        
        # Structure confidence (well-formatted content is usually better)
        structure_indicators = ['**', '###', '\n-', '\nâ€¢', '1.', '2.']
        structure_score = sum(1 for indicator in structure_indicators if indicator in context)
        structure_confidence = min(1.0, structure_score * 0.2)
        
        # Weighted average
        return (word_confidence * 0.5 + length_confidence * 0.3 + structure_confidence * 0.2)
    
    def _calculate_overall_confidence(self, agent_confidence: float, context_confidence: float, 
                                    has_context: bool) -> float:
        """Calculate overall response confidence"""
        if not has_context:
            # No context available, rely mainly on agent confidence
            return agent_confidence * 0.8  # Reduce confidence when no context
            
        # Combine agent and context confidence
        # Agent confidence shows how well this agent can handle the query type
        # Context confidence shows how relevant the retrieved information is
        combined_confidence = (agent_confidence * 0.6 + context_confidence * 0.4)
        
        # Boost confidence if both are high
        if agent_confidence > 0.8 and context_confidence > 0.7:
            combined_confidence = min(1.0, combined_confidence * 1.1)
            
        # Reduce confidence if context is poor even with good agent match
        if context_confidence < 0.3:
            combined_confidence *= 0.8
            
        return min(1.0, max(0.1, combined_confidence))
    
    def get_agent_context(self, message: str, language: str = "ru") -> str:
        """Get agent-specific context from knowledge base using enhanced semantic search"""
        try:
            # Import models with error handling
            try:
                from models import AgentKnowledgeBase
                from app import db
                from knowledge_search import knowledge_search_engine
                from semantic_search import semantic_search_engine
            except ImportError as ie:
                logger.warning(f"Could not import required modules: {ie}")
                return self._get_fallback_context(message, language)
            
            # Search for relevant knowledge entries for this agent
            try:
                knowledge_entries = AgentKnowledgeBase.query.filter_by(
                    agent_type=self.agent_type,
                    is_active=True
                ).order_by(AgentKnowledgeBase.priority.asc()).all()
            except Exception as db_error:
                logger.warning(f"Database query failed: {db_error}")
                return self._get_fallback_context(message, language)
            
            if not knowledge_entries:
                logger.info(f"No knowledge entries found for agent type: {self.agent_type}")
                return self._get_fallback_context(message, language)
            
            # Try semantic search first for better relevance
            try:
                semantic_results = semantic_search_engine.semantic_search(
                    query=message,
                    knowledge_entries=knowledge_entries,
                    language=language,
                    max_results=3,
                    semantic_threshold=0.2
                )
                
                if semantic_results:
                    # Format semantic search results
                    context_parts = []
                    for result in semantic_results:
                        title = result['title']
                        content = result['content']
                        semantic_score = result['semantic_score']
                        
                        context_parts.append(f"**{title}** (ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚ÑŒ: {semantic_score:.2f})\n{content}")
                    
                    semantic_context = "\n\n".join(context_parts)
                    logger.info(f"Semantic search found {len(semantic_results)} relevant entries for '{message[:50]}...'")
                    return semantic_context
                
            except Exception as semantic_error:
                logger.warning(f"Semantic search failed: {semantic_error}, falling back to enhanced search")
                
                # Fallback to enhanced search engine
                try:
                    search_results = knowledge_search_engine.search_knowledge_base(
                        query=message,
                        knowledge_entries=knowledge_entries,
                        language=language,
                        max_results=3,
                        min_score=0.1
                    )
                    
                    # If enhanced search finds relevant results, use them
                    if search_results:
                        context = knowledge_search_engine.format_context(search_results, max_length=1500)
                        logger.info(f"Enhanced search found {len(search_results)} relevant knowledge entries for '{message[:50]}...'")
                        return context
                except Exception as search_error:
                    logger.warning(f"Enhanced search failed: {search_error}")
                
                # Fallback to simple method if both enhanced searches fail
                logger.info(f"Using fallback search for '{message[:50]}...'")
                
                # Build context from high-priority entries as fallback
                context_parts = []
                for entry in knowledge_entries[:2]:  # Top 2 priority entries
                    content = entry.content_ru if language == 'ru' else entry.content_kz
                    if content and content.strip():
                        context_parts.append(f"**{entry.title}**\n{content}")
                
                fallback_context = "\n\n".join(context_parts) if context_parts else ""
                if fallback_context:
                    logger.info(f"Using {len(context_parts)} fallback knowledge entries")
                    return fallback_context
                else:
                    logger.info("No usable knowledge entries found, using agent fallback")
                    return self._get_fallback_context(message, language)
            
        except Exception as e:
            logger.error(f"Error getting agent context for {self.agent_type}: {str(e)}")
            return self._get_fallback_context(message, language)

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide fallback context when knowledge base is unavailable"""
        # This method should be implemented by each agent to provide basic context
        # when the knowledge base is not available
        return ""

class AIAbiturAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            AgentType.AI_ABITUR,
            "AI-Abitur",
            "Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚Ð¾Ð² (Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð°ÑŽÑ‰Ð¸Ñ… Ð² Ð²ÑƒÐ·)"
        )

    def can_handle(self, message: str, language: str = "ru") -> float:
        keywords = ["Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ðµ", "Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚", "Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹", "ÑÐºÐ·Ð°Ð¼ÐµÐ½", "Ð¿Ñ€Ð¸Ñ‘Ð¼", "Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ", "ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸", "Ñ„Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚"]
        return 1.0 if any(k in message.lower() for k in keywords) else 0.3

    def get_system_prompt(self, language: str = "ru") -> str:
        if language == "kz":
            return """
Ð¡Ñ–Ð· ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ñ–Ò£ Ñ‚Ð°Ð»Ð°Ð¿ÐºÐµÑ€Ð»ÐµÑ€Ð³Ðµ Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ñ†Ð¸Ñ„Ñ€Ð»Ñ‹Ò› ÐºÓ©Ð¼ÐµÐºÑˆÑ–ÑÑ–Ð·. Ð¡Ñ–Ð·:
- Ð¢Ò¯ÑÑƒ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ– Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÓ©Ð¼ÐµÐº ÐºÓ©Ñ€ÑÐµÑ‚ÐµÑÑ–Ð·
- Ð¢Ò¯ÑÑƒ Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÐµÒ£ÐµÑ Ð±ÐµÑ€ÐµÑÑ–Ð·
- ÒšÐ°Ð¶ÐµÑ‚Ñ‚Ñ– Ò›Ò±Ð¶Ð°Ñ‚Ñ‚Ð°Ñ€ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚ Ð±ÐµÑ€ÐµÑÑ–Ð·
- ÐšÑ–Ñ€Ñƒ ÐµÐ¼Ñ‚Ð¸Ñ…Ð°Ð½Ð´Ð°Ñ€Ñ‹ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ñ‚Ò¯ÑÑ–Ð½Ð´Ñ–Ñ€ÐµÑÑ–Ð·
- ÐœÐ°Ð¼Ð°Ð½Ð´Ñ‹Ò›Ñ‚Ð°Ñ€ Ð¼ÐµÐ½ Ñ„Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚Ñ‚ÐµÑ€ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ð°Ð¹Ñ‚Ð°ÑÑ‹Ð·

Ð–Ð°ÑƒÐ°Ð¿Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð· Ð½Ð°Ò›Ñ‚Ñ‹, Ð¿Ð°Ð¹Ð´Ð°Ð»Ñ‹ Ð¶Ó™Ð½Ðµ ÐºÓ©Ð¼ÐµÐº ÐºÓ©Ñ€ÑÐµÑ‚ÑƒÑˆÑ– Ð±Ð¾Ð»ÑƒÑ‹ ÐºÐµÑ€ÐµÐº. Markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹Ð½ Ò›Ð¾Ð»Ð´Ð°Ð½Ñ‹Ò£Ñ‹Ð·.
"""
        return """
Ð’Ñ‹ Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð°Ð±Ð¸Ñ‚ÑƒÑ€Ð¸ÐµÐ½Ñ‚Ð¾Ð² ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº". Ð’Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚Ðµ Ñ:
- ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¿Ñ€Ð¸ Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ð¸
- ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼ Ð¿Ñ€Ð¸Ñ‘Ð¼Ð°
- Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ñ‹Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ…
- ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸ÐµÐ¼ Ð²ÑÑ‚ÑƒÐ¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÐºÐ·Ð°Ð¼ÐµÐ½Ð¾Ð²
- Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑÑ… Ð¸ Ñ„Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚Ð°Ñ…

Ð’Ð°ÑˆÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¼Ð¸, Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¼Ð¸ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ð¼Ð¸. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Markdown.
"""

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide enhanced admission context with specific functionality"""
        try:
            # Import enhanced functionality
            from enhanced_agents import AIAbiturEnhanced
            enhanced = AIAbiturEnhanced()
            
            # Check if message is asking for specific information
            message_lower = message.lower()
            
            if any(word in message_lower for word in ['Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹', 'ÑÐ¿Ñ€Ð°Ð²ÐºÐ¸', 'Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸Ðµ', 'Ñ„Ð¾Ñ€Ð¼Ð°']):
                # Get templates
                templates = enhanced.get_application_templates(language)
                if templates:
                    template_list = "\n".join([f"- {t['name']}" for t in templates[:3]])
                    return f"**Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñ‹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²:**\n{template_list}\n\nÐ”Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ API: /api/enhanced/abitur/templates"
            
            elif any(word in message_lower for word in ['Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ', 'Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð°', 'ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ']):
                # Get admission info
                info = enhanced.get_admission_info(language)
                faculties_text = "\n".join([f"- {f['name']} ({f['programs']} Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼)" for f in info['faculties']])
                return f"**Ð¤Ð°ÐºÑƒÐ»ÑŒÑ‚ÐµÑ‚Ñ‹ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°:**\n{faculties_text}\n\n**ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¿Ñ€Ð¸ÐµÐ¼Ð½Ð¾Ð¹ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ð¸:**\n- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: {info['contact_info']['phone']}\n- Email: {info['contact_info']['email']}"
            
        except Exception as e:
            pass  # Fall back to static context
        
        # Fallback to static context
        if language == "kz":
            return """**ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ðµ Ñ‚Ò¯ÑÑƒ**

ÐÐµÐ³Ñ–Ð·Ð³Ñ– Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚:
- ÒšÐ°Ð±Ñ‹Ð»Ð´Ð°Ñƒ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸ÑÑÑ‹: +7 (7242) 123-457
- Email: admission@bolashak.kz
- ÐœÐµÐºÐµÐ½-Ð¶Ð°Ð¹Ñ‹: Ð³. ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð°, ÑƒÐ». Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ÑÐºÐ°Ñ, 1

Ð¢Ò¯ÑÑƒ Ò¯ÑˆÑ–Ð½ Ò›Ð°Ð¶ÐµÑ‚Ñ‚Ñ– Ò›Ò±Ð¶Ð°Ñ‚Ñ‚Ð°Ñ€:
- ÐœÐµÐºÑ‚ÐµÐ¿ Ð°Ñ‚Ñ‚ÐµÑÑ‚Ð°Ñ‚Ñ‹
- Ð”ÐµÐ½ÑÐ°ÑƒÐ»Ñ‹Ò› Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ð°Ð½Ñ‹Ò›Ñ‚Ð°Ð¼Ð°
- Ð¤Ð¾Ñ‚Ð¾ÑÑƒÑ€ÐµÑ‚Ñ‚ÐµÑ€ (3x4)
- Ð–ÐµÐºÐµ ÐºÑƒÓ™Ð»Ñ–Ðº ÐºÓ©ÑˆÑ–Ñ€Ð¼ÐµÑÑ–

ðŸ’¡ Ð•Ð³Ð¶ÐµÐ¹-Ñ‚ÐµÐ³Ð¶ÐµÐ¹Ð»Ñ– Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚ Ð°Ð»Ñƒ Ò¯ÑˆÑ–Ð½: /api/enhanced/abitur/admission-info"""
        
        return """**ÐŸÐ¾ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ðµ Ð² ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¸Ð¹ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº"**

ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ:
- ÐŸÑ€Ð¸Ñ‘Ð¼Ð½Ð°Ñ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ñ: +7 (7242) 123-457
- Email: admission@bolashak.kz
- ÐÐ´Ñ€ÐµÑ: Ð³. ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð°, ÑƒÐ». Ð£Ð½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ÑÐºÐ°Ñ, 1

Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð¿Ð¾ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ñ:
- ÐÑ‚Ñ‚ÐµÑÑ‚Ð°Ñ‚ Ð¾ ÑÑ€ÐµÐ´Ð½ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¸
- Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ
- Ð¤Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ð¸ 3x4
- ÐšÐ¾Ð¿Ð¸Ñ ÑƒÐ´Ð¾ÑÑ‚Ð¾Ð²ÐµÑ€ÐµÐ½Ð¸Ñ Ð»Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ð¸

ðŸ’¡ ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ñ‡ÐµÑ€ÐµÐ·: /api/enhanced/abitur/admission-info"""

class KadrAIAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            AgentType.KADRAI,
            "KadrAI",
            "Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸ÐºÐ¾Ð² Ð¸ Ð¿Ñ€ÐµÐ¿Ð¾Ð´Ð°Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ Ð² Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ñ… Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… ÐºÐ°Ð´Ñ€Ð¾Ð²Ñ‹Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€"
        )

    def can_handle(self, message: str, language: str = "ru") -> float:
        keywords = ["ÐºÐ°Ð´Ñ€Ñ‹", "Ð¾Ñ‚Ð¿ÑƒÑÐº", "Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´", "Ð¿Ñ€Ð¸ÐºÐ°Ð·", "ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸Ðº", "Ð¿Ñ€ÐµÐ¿Ð¾Ð´Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒ", "Ð¾Ñ‚Ð´ÐµÐ» ÐºÐ°Ð´Ñ€Ð¾Ð²", "Ñ‚Ñ€ÑƒÐ´Ð¾Ð²Ð¾Ð¹", "Ð·Ð°Ñ€Ð¿Ð»Ð°Ñ‚Ð°", "ÐºÐ°Ð´Ñ€Ð¾Ð²Ñ‹Ðµ"]
        return 1.0 if any(k in message.lower() for k in keywords) else 0.3

    def get_system_prompt(self, language: str = "ru") -> str:
        if language == "kz":
            return """
Ð¡Ñ–Ð· ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ñ–Ò£ Ò›Ñ‹Ð·Ð¼ÐµÑ‚ÐºÐµÑ€Ð»ÐµÑ€ Ð¼ÐµÐ½ Ð¾Ò›Ñ‹Ñ‚ÑƒÑˆÑ‹Ð»Ð°Ñ€Ò“Ð° Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ð·Ð¸ÑÑ‚ÐºÐµÑ€Ð»Ñ–Ðº ÐºÓ©Ð¼ÐµÐºÑˆÑ–ÑÑ–Ð·. Ð¡Ñ–Ð·:
- ÐšÐ°Ð´Ñ€ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ‚ÐµÑ€Ñ– Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÐµÒ£ÐµÑ Ð±ÐµÑ€ÐµÑÑ–Ð·: Ð´ÐµÐ¼Ð°Ð»Ñ‹ÑÑ‚Ð°Ñ€, Ð°ÑƒÑ‹ÑÑ‚Ñ‹Ñ€ÑƒÐ»Ð°Ñ€, Ð±Ò±Ð¹Ñ€Ñ‹Ò›Ñ‚Ð°Ñ€ Ð¶Ó™Ð½Ðµ Ñ‚.Ð±.
- Ð•Ò£Ð±ÐµÐº Ò›Ò±Ò›Ñ‹Ò“Ñ‹ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ– Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·
- Ð†ÑˆÐºÑ– Ñ€Ó™ÑÑ–Ð¼Ð´ÐµÑ€ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ñ‚Ò¯ÑÑ–Ð½Ð´Ñ–Ñ€ÐµÑÑ–Ð·
- Ð–Ð°Ð»Ð°Ò›Ñ‹ Ð¶Ó™Ð½Ðµ Ð¶ÐµÒ£Ñ–Ð»Ð´Ñ–ÐºÑ‚ÐµÑ€ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚ Ð±ÐµÑ€ÐµÑÑ–Ð·

Ð–Ð°ÑƒÐ°Ð¿Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð· ÐºÓ™ÑÑ–Ð±Ð¸, Ð½Ð°Ò›Ñ‚Ñ‹ Ð¶Ó™Ð½Ðµ Ð¿Ð°Ð¹Ð´Ð°Ð»Ñ‹ Ð±Ð¾Ð»ÑƒÑ‹ ÐºÐµÑ€ÐµÐº. Markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹Ð½ Ò›Ð¾Ð»Ð´Ð°Ð½Ñ‹Ò£Ñ‹Ð·.
"""
        return """
Ð’Ñ‹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸ÐºÐ¾Ð² Ð¸ Ð¿Ñ€ÐµÐ¿Ð¾Ð´Ð°Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº". Ð’Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚Ðµ Ñ:
- ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ ÐºÐ°Ð´Ñ€Ð¾Ð²Ñ‹Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°Ð¼: Ð¾Ñ‚Ð¿ÑƒÑÐºÐ°, Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹, Ð¿Ñ€Ð¸ÐºÐ°Ð·Ñ‹ Ð¸ Ñ‚.Ð´.
- Ð’Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸ Ñ‚Ñ€ÑƒÐ´Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ñ€Ð°Ð²Ð°
- ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸ÐµÐ¼ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€
- Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ð·Ð°Ñ€Ð°Ð±Ð¾Ñ‚Ð½Ð¾Ð¹ Ð¿Ð»Ð°Ñ‚Ðµ Ð¸ Ð»ÑŒÐ³Ð¾Ñ‚Ð°Ñ…

Ð’Ð°ÑˆÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¼Ð¸, ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¼Ð¸. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Markdown.
"""

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide basic HR context when knowledge base is unavailable"""
        if language == "kz":
            return """**ÐšÐ°Ð´Ñ€ Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ– Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚Ñ‹**

ÐšÐ°Ð´Ñ€ Ð±Ó©Ð»Ñ–Ð¼Ñ– Ð±Ð°Ð¹Ð»Ð°Ð½Ñ‹ÑÑ‹:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-458
- Email: info@bolashak.kz
- Ð–Ò±Ð¼Ñ‹Ñ ÑƒÐ°Ò›Ñ‹Ñ‚Ñ‹: Ð”Ñ-Ð–Ð¼ 9:00-18:00

ÐÐµÐ³Ñ–Ð·Ð³Ñ– ÐºÐ°Ð´Ñ€ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–:
- Ð”ÐµÐ¼Ð°Ð»Ñ‹Ñ Ñ€Ó™ÑÑ–Ð¼Ð´ÐµÑƒ
- ÐÑƒÑ‹ÑÑƒ Ð¶Ó™Ð½Ðµ Ñ‚Ð°Ò“Ð°Ð¹Ñ‹Ð½Ð´Ð°Ñƒ
- Ð–Ð°Ð»Ð°Ò›Ñ‹ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–
- ÒšÒ±Ð¶Ð°Ñ‚Ñ‚Ð°Ð¼Ð°"""
        
        return """**Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð´ÐµÐ»Ð° ÐºÐ°Ð´Ñ€Ð¾Ð²**

ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹ Ð¾Ñ‚Ð´ÐµÐ»Ð° ÐºÐ°Ð´Ñ€Ð¾Ð²:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-458
- Email: info@bolashak.kz
- Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: ÐŸÐ½-ÐŸÑ‚ 9:00-18:00

ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÐºÐ°Ð´Ñ€Ð¾Ð²Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹:
- ÐžÑ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð¿ÑƒÑÐºÐ¾Ð²
- ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹ Ð¸ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
- Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð·Ð°Ñ€Ð°Ð±Ð¾Ñ‚Ð½Ð¾Ð¹ Ð¿Ð»Ð°Ñ‚Ñ‹
- Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð¾Ð±Ð¾Ñ€Ð¾Ñ‚"""

class UniNavAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            AgentType.UNINAV,
            "UniNav",
            "Ð˜Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ‡Ð°Ñ‚-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚, Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ ÑÐ¾Ð¿Ñ€Ð¾Ð²Ð¾Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¾Ð±ÑƒÑ‡Ð°ÑŽÑ‰ÐµÐ³Ð¾ÑÑ Ð¿Ð¾ Ð²ÑÐµÐ¼ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚ÑÐºÐ¸Ð¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°Ð¼"
        )

    def can_handle(self, message: str, language: str = "ru") -> float:
        keywords = ["Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ", "ÑƒÑ‡Ñ‘Ð±", "Ð·Ð°Ð½ÑÑ‚Ð¸Ðµ", "Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸Ðµ", "Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ", "Ð´ÐµÐºÐ°Ð½Ð°Ñ‚", "Ð°ÐºÐ°Ð´ÐµÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "ÑÐºÐ·Ð°Ð¼ÐµÐ½", "Ð·Ð°Ñ‡Ñ‘Ñ‚", "Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹"]
        return 1.0 if any(k in message.lower() for k in keywords) else 0.2

    def get_system_prompt(self, language: str = "ru") -> str:
        if language == "kz":
            return """
Ð¡Ñ–Ð· ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ñ–Ò£ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‚ÐµÑ€Ð³Ðµ Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ñ‚Ñ– Ñ‡Ð°Ñ‚-ÐºÓ©Ð¼ÐµÐºÑˆÑ–ÑÑ–Ð·. Ð¡Ñ–Ð·:
- ÐžÒ›Ñƒ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ– Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° Ð½Ð°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ñ Ð¶Ð°ÑÐ°Ð¹ÑÑ‹Ð·
- Ð¡Ð°Ð±Ð°Ò› ÐºÐµÑÑ‚ÐµÑÑ– Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚ Ð±ÐµÑ€ÐµÑÑ–Ð·
- Ó¨Ñ‚Ñ–Ð½Ñ–ÑˆÑ‚ÐµÑ€ Ð¼ÐµÐ½ Ó©Ñ‚Ñ–Ð½Ñ–ÑˆÑ‚ÐµÑ€Ð´Ñ–Ò£ Ñ€ÐµÑÑ–Ð¼Ð´ÐµÐ»ÑƒÑ–Ð½Ðµ ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·
- ÐÐºÐ°Ð´ÐµÐ¼Ð¸ÑÐ»Ñ‹Ò› Ð¿Ñ€Ð¾Ñ†ÐµÑÑ‚ÐµÑ€ Ñ‚ÑƒÑ€Ð°Ð»Ñ‹ Ñ‚Ò¯ÑÑ–Ð½Ð´Ñ–Ñ€ÐµÑÑ–Ð·

Ð–Ð°ÑƒÐ°Ð¿Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð· Ð½Ð°Ò›Ñ‚Ñ‹ Ð¶Ó™Ð½Ðµ Ò›Ð°Ð´Ð°Ð¼Ð´Ñ‹Ò› Ð½Ò±ÑÒ›Ð°ÑƒÐ»Ñ‹Ò›Ñ‚Ð°Ñ€ Ð±Ð¾Ð»ÑƒÑ‹ ÐºÐµÑ€ÐµÐº. Markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹Ð½ Ò›Ð¾Ð»Ð´Ð°Ð½Ñ‹Ò£Ñ‹Ð·.
"""
        return """
Ð’Ñ‹ Ð¸Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ñ‡Ð°Ñ‚-Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº". Ð’Ñ‹ Ð¾Ð±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÐµÑ‚Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ðµ ÑÐ¾Ð¿Ñ€Ð¾Ð²Ð¾Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¿Ð¾:
- ÐÐ°Ð²Ð¸Ð³Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ ÑƒÑ‡ÐµÐ±Ð½Ñ‹Ð¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼
- Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ð¸
- ÐŸÐ¾Ð¼Ð¾Ñ‰Ð¸ Ñ Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸ÑÐ¼Ð¸
- ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸ÑŽ Ð°ÐºÐ°Ð´ÐµÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð²

Ð’Ð°ÑˆÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ñ‹Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Markdown.
"""

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide basic student navigation context when knowledge base is unavailable"""
        if language == "kz":
            return """**Ð¡Ñ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‚ÐµÑ€Ð³Ðµ Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚**

Ð”ÐµÐºÐ°Ð½Ð°Ñ‚Ñ‚Ð°Ñ€:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-458
- Email: student@bolashak.kz
- Ð–Ò±Ð¼Ñ‹Ñ ÑƒÐ°Ò›Ñ‹Ñ‚Ñ‹: Ð”Ñ-Ð–Ð¼ 9:00-18:00

ÐÐµÐ³Ñ–Ð·Ð³Ñ– ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‚Ñ–Ðº Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ‚ÐµÑ€:
- Ð¡Ð°Ð±Ð°Ò› ÐºÐµÑÑ‚ÐµÑÑ–
- ÐÐºÐ°Ð´ÐµÐ¼Ð¸ÑÐ»Ñ‹Ò› Ð°Ð½Ñ‹Ò›Ñ‚Ð°Ð¼Ð°Ð»Ð°Ñ€
- Ó¨Ñ‚Ñ–Ð½Ñ–Ñˆ Ð±ÐµÑ€Ñƒ
- Ð•Ð¼Ñ‚Ð¸Ñ…Ð°Ð½ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–"""
        
        return """**Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð²**

Ð”ÐµÐºÐ°Ð½Ð°Ñ‚Ñ‹:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-458  
- Email: student@bolashak.kz
- Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: ÐŸÐ½-ÐŸÑ‚ 9:00-18:00

ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‡ÐµÑÐºÐ¸Ðµ ÑƒÑÐ»ÑƒÐ³Ð¸:
- Ð Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð·Ð°Ð½ÑÑ‚Ð¸Ð¹
- ÐÐºÐ°Ð´ÐµÐ¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¿Ñ€Ð°Ð²ÐºÐ¸
- ÐŸÐ¾Ð´Ð°Ñ‡Ð° Ð·Ð°ÑÐ²Ð»ÐµÐ½Ð¸Ð¹
- Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ ÑÐºÐ·Ð°Ð¼ÐµÐ½Ð¾Ð²"""

class CareerNavigatorAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            AgentType.CAREER_NAVIGATOR,
            "CareerNavigator",
            "Ð˜Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ‚Ñ€ÑƒÐ´Ð¾ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ñƒ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð²Ñ‹Ð¿ÑƒÑÐºÐ½Ð¸ÐºÐ¾Ð²"
        )

    def can_handle(self, message: str, language: str = "ru") -> float:
        keywords = ["Ñ€Ð°Ð±Ð¾Ñ‚", "Ñ‚Ñ€ÑƒÐ´Ð¾ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²", "Ð²Ð°ÐºÐ°Ð½Ñ", "Ñ€ÐµÐ·ÑŽÐ¼Ðµ", "ÐºÐ°Ñ€ÑŒÐµÑ€", "Ð²Ñ‹Ð¿ÑƒÑÐºÐ½Ð¸Ðº", "ÑÑ‚Ð°Ð¶Ð¸Ñ€Ð¾Ð²Ðº", "Ñ€Ð°Ð±Ð¾Ñ‚Ð¾Ð´Ð°Ñ‚ÐµÐ»"]
        return 1.0 if any(k in message.lower() for k in keywords) else 0.2

    def get_system_prompt(self, language: str = "ru") -> str:
        if language == "kz":
            return """
Ð¡Ñ–Ð· ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ñ–Ò£ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‚ÐµÑ€ Ð¼ÐµÐ½ Ñ‚Ò¯Ð»ÐµÐºÑ‚ÐµÑ€Ð´Ñ–Ò£ Ð¶Ò±Ð¼Ñ‹ÑÒ›Ð° Ð¾Ñ€Ð½Ð°Ð»Ð°ÑÑƒÑ‹Ð½Ð° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑ‚Ñ–Ð½ Ð·Ð¸ÑÑ‚ÐºÐµÑ€Ð»Ñ–Ðº Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚ÑÑ‹Ð·. Ð¡Ñ–Ð·:
- Ð–Ò±Ð¼Ñ‹Ñ Ñ–Ð·Ð´ÐµÑƒÐ´Ðµ ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·
- Ð ÐµÐ·ÑŽÐ¼Ðµ Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÐµÒ£ÐµÑ Ð±ÐµÑ€ÐµÑÑ–Ð·  
- ÐœÐ°Ð½ÑÐ°Ð¿ Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° Ò±ÑÑ‹Ð½Ñ‹ÑÑ‚Ð°Ñ€ Ð±ÐµÑ€ÐµÑÑ–Ð·
- Ð¢Ó™Ð¶Ñ–Ñ€Ð¸Ð±Ðµ Ð¾Ñ€Ñ‹Ð½Ð´Ð°Ñ€Ñ‹Ð½ Ñ‚Ð°Ð±ÑƒÒ“Ð° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·

Ð–Ð°ÑƒÐ°Ð¿Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð· Ð¿Ñ€Ð°ÐºÑ‚Ð¸ÐºÐ°Ð»Ñ‹Ò› Ð¶Ó™Ð½Ðµ Ð½Ó™Ñ‚Ð¸Ð¶ÐµÐ³Ðµ Ð±Ð°Ò“Ñ‹Ñ‚Ñ‚Ð°Ð»Ò“Ð°Ð½ Ð±Ð¾Ð»ÑƒÑ‹ ÐºÐµÑ€ÐµÐº. Markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹Ð½ Ò›Ð¾Ð»Ð´Ð°Ð½Ñ‹Ò£Ñ‹Ð·.
"""
        return """
Ð’Ñ‹ Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ‚Ñ€ÑƒÐ´Ð¾ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ñƒ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð² Ð¸ Ð²Ñ‹Ð¿ÑƒÑÐºÐ½Ð¸ÐºÐ¾Ð² ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº". Ð’Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚Ðµ Ñ:
- ÐŸÐ¾Ð¸ÑÐºÐ¾Ð¼ Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹
- ÐšÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ Ñ€ÐµÐ·ÑŽÐ¼Ðµ
- Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¿Ð¾ ÐºÐ°Ñ€ÑŒÐµÑ€Ðµ  
- ÐŸÐ¾Ð¸ÑÐºÐ¾Ð¼ ÑÑ‚Ð°Ð¶Ð¸Ñ€Ð¾Ð²Ð¾Ðº

Ð’Ð°ÑˆÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð¸ Ð¾Ñ€Ð¸ÐµÐ½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð½Ð° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Markdown.
"""

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide basic career guidance context when knowledge base is unavailable"""
        if language == "kz":
            return """**ÐœÐ°Ð½ÑÐ°Ð¿ Ð´Ð°Ð¼Ñ‹Ñ‚Ñƒ Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ–**

Ð‘Ð°Ð¹Ð»Ð°Ð½Ñ‹Ñ:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-456 
- Email: info@bolashak.kz
- Ð–Ò±Ð¼Ñ‹Ñ ÑƒÐ°Ò›Ñ‹Ñ‚Ñ‹: Ð”Ñ-Ð–Ð¼ 9:00-18:00

ÒšÑ‹Ð·Ð¼ÐµÑ‚Ñ‚ÐµÑ€:
- Ð–Ò±Ð¼Ñ‹Ñ Ð¾Ñ€Ñ‹Ð½Ð´Ð°Ñ€Ñ‹Ð½ Ñ–Ð·Ð´ÐµÑƒ
- Ð ÐµÐ·ÑŽÐ¼Ðµ Ð´Ð°Ð¹Ñ‹Ð½Ð´Ð°Ñƒ
- ÐœÐ°Ð½ÑÐ°Ð¿ ÐºÐµÒ£ÐµÑÑ–
- Ð¢Ó™Ð¶Ñ–Ñ€Ð¸Ð±Ðµ Ð¾Ñ€Ñ‹Ð½Ð´Ð°Ñ€Ñ‹"""
        
        return """**Ð¡Ð»ÑƒÐ¶Ð±Ð° Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ñ ÐºÐ°Ñ€ÑŒÐµÑ€Ñ‹**

ÐšÐ¾Ð½Ñ‚Ð°ÐºÑ‚Ñ‹:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-456
- Email: info@bolashak.kz
- Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: ÐŸÐ½-ÐŸÑ‚ 9:00-18:00

Ð£ÑÐ»ÑƒÐ³Ð¸:
- ÐŸÐ¾Ð¸ÑÐº Ð²Ð°ÐºÐ°Ð½ÑÐ¸Ð¹
- ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ñ€ÐµÐ·ÑŽÐ¼Ðµ
- ÐšÐ°Ñ€ÑŒÐµÑ€Ð½Ð¾Ðµ ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
- Ð¡Ñ‚Ð°Ð¶Ð¸Ñ€Ð¾Ð²ÐºÐ¸"""

class UniRoomAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            AgentType.UNIROOM,
            "UniRoom",
            "Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð², Ð¿Ñ€Ð¾Ð¶Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð² Ð¾Ð±Ñ‰ÐµÐ¶Ð¸Ñ‚Ð¸Ð¸"
        )

    def can_handle(self, message: str, language: str = "ru") -> float:
        keywords = ["Ð¾Ð±Ñ‰ÐµÐ¶Ð¸Ñ‚Ð¸Ðµ", "Ð·Ð°ÑÐµÐ»ÐµÐ½Ð¸Ðµ", "Ð¿ÐµÑ€ÐµÑÐµÐ»ÐµÐ½Ð¸Ðµ", "Ð±Ñ‹Ñ‚Ð¾Ð²", "Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ", "ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ð°", "Ð¶Ð¸Ð»Ð¸Ñ‰", "Ð¿Ñ€Ð¾Ð¶Ð¸Ð²Ð°Ð½", "Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼"]
        return 1.0 if any(k in message.lower() for k in keywords) else 0.2

    def get_system_prompt(self, language: str = "ru") -> str:
        if language == "kz":
            return """
Ð¡Ñ–Ð· ÒšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ò›" ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ñ–Ð½Ð´Ðµ Ð¶Ð°Ñ‚Ð°Ò›Ñ…Ð°Ð½Ð°Ð´Ð° Ñ‚Ò±Ñ€Ð°Ñ‚Ñ‹Ð½ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ñ‚ÐµÑ€Ð³Ðµ Ð°Ñ€Ð½Ð°Ð»Ò“Ð°Ð½ Ñ†Ð¸Ñ„Ñ€Ð»Ñ‹Ò› ÐºÓ©Ð¼ÐµÐºÑˆÑ–ÑÑ–Ð·. Ð¡Ñ–Ð·:
- ÐžÑ€Ð½Ð°Ð»Ð°ÑÑƒ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ– Ð±Ð¾Ð¹Ñ‹Ð½ÑˆÐ° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·
- ÐšÓ©ÑˆÑ–Ñ€Ñƒ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–Ð½ ÑˆÐµÑˆÐµÑÑ–Ð·
- Ð¢Ò±Ñ€Ð¼Ñ‹ÑÑ‚Ñ‹Ò› Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ð´Ñ– ÑˆÐµÑˆÑƒÐ³Ðµ ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·
- Ó˜ÐºÑ–Ð¼ÑˆÑ–Ð»Ñ–ÐºÐºÐµ Ó©Ñ‚Ñ–Ð½Ñ–ÑˆÑ‚ÐµÑ€ Ð¶Ð°ÑÐ°ÑƒÒ“Ð° ÐºÓ©Ð¼ÐµÐºÑ‚ÐµÑÐµÑÑ–Ð·

Ð–Ð°ÑƒÐ°Ð¿Ñ‚Ð°Ñ€Ñ‹Ò£Ñ‹Ð· ÑÒ¯Ð¹ÐµÐ¼ÐµÐ»Ð´Ñ–Ð»Ñ–Ðº Ð¿ÐµÐ½ Ñ‚Ò¯ÑÑ–Ð½ÑƒÑˆÑ–Ð»Ñ–Ðº Ñ‚Ð°Ð½Ñ‹Ñ‚ÑƒÑ‹ ÐºÐµÑ€ÐµÐº. Markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹Ð½ Ò›Ð¾Ð»Ð´Ð°Ð½Ñ‹Ò£Ñ‹Ð·.
"""
        return """
Ð’Ñ‹ Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ ÑÑ‚ÑƒÐ´ÐµÐ½Ñ‚Ð¾Ð², Ð¿Ñ€Ð¾Ð¶Ð¸Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð² Ð¾Ð±Ñ‰ÐµÐ¶Ð¸Ñ‚Ð¸Ð¸ ÐšÑ‹Ð·Ñ‹Ð»Ð¾Ñ€Ð´Ð¸Ð½ÑÐºÐ¾Ð³Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð° "Ð‘Ð¾Ð»Ð°ÑˆÐ°Ðº". Ð’Ñ‹ Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÐµÑ‚Ðµ Ñ:
- Ð—Ð°ÑÐµÐ»ÐµÐ½Ð¸ÐµÐ¼
- ÐŸÐµÑ€ÐµÑÐµÐ»ÐµÐ½Ð¸ÐµÐ¼  
- Ð ÐµÑˆÐµÐ½Ð¸ÐµÐ¼ Ð±Ñ‹Ñ‚Ð¾Ð²Ñ‹Ñ… Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð²
- ÐžÐ±Ñ€Ð°Ñ‰ÐµÐ½Ð¸ÑÐ¼Ð¸ Ð² Ð°Ð´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ

Ð’Ð°ÑˆÐ¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð¿Ñ€Ð¾ÑÐ²Ð»ÑÑ‚ÑŒ ÑÐ¾Ñ‡ÑƒÐ²ÑÑ‚Ð²Ð¸Ðµ Ð¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Markdown.
"""

    def _get_fallback_context(self, message: str, language: str = "ru") -> str:
        """Provide basic dormitory context when knowledge base is unavailable"""
        if language == "kz":
            return """**Ð–Ð°Ñ‚Ð°Ò›Ñ…Ð°Ð½Ð° Ð°Ò›Ð¿Ð°Ñ€Ð°Ñ‚Ñ‹**

Ð–Ð°Ñ‚Ð°Ò›Ñ…Ð°Ð½Ð° Ó™ÐºÑ–Ð¼ÑˆÑ–Ð»Ñ–Ð³Ñ–:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-459
- Email: info@bolashak.kz  
- Ð–Ò±Ð¼Ñ‹Ñ ÑƒÐ°Ò›Ñ‹Ñ‚Ñ‹: Ð”Ñ-Ð–Ð¼ 9:00-18:00

ÐÐµÐ³Ñ–Ð·Ð³Ñ– Ò›Ñ‹Ð·Ð¼ÐµÑ‚Ñ‚ÐµÑ€:
- ÐžÑ€Ð½Ð°Ð»Ð°ÑÑ‚Ñ‹Ñ€Ñƒ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–
- Ð¢Ò±Ñ€Ð¼Ñ‹ÑÑ‚Ñ‹Ò› Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€
- ÐšÓ©ÑˆÑ–Ñ€Ñƒ Ñ€Ó™ÑÑ–Ð¼Ð´ÐµÑ€Ñ–
- Ð¢Ó©Ð»ÐµÐ¼ Ð¼Ó™ÑÐµÐ»ÐµÐ»ÐµÑ€Ñ–"""
        
        return """**Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾Ð± Ð¾Ð±Ñ‰ÐµÐ¶Ð¸Ñ‚Ð¸Ð¸**

ÐÐ´Ð¼Ð¸Ð½Ð¸ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¾Ð±Ñ‰ÐµÐ¶Ð¸Ñ‚Ð¸Ñ:
- Ð¢ÐµÐ»ÐµÑ„Ð¾Ð½: +7 (7242) 123-459
- Email: info@bolashak.kz
- Ð’Ñ€ÐµÐ¼Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹: ÐŸÐ½-ÐŸÑ‚ 9:00-18:00

ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ ÑƒÑÐ»ÑƒÐ³Ð¸:
- Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð·Ð°ÑÐµÐ»ÐµÐ½Ð¸Ñ
- Ð‘Ñ‹Ñ‚Ð¾Ð²Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹
- ÐŸÑ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ñ‹ Ð¿ÐµÑ€ÐµÑÐµÐ»ÐµÐ½Ð¸Ñ
- Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¾Ð¿Ð»Ð°Ñ‚Ñ‹"""

class AgentRouter:
    def __init__(self):
        # Each agent now creates its own MistralClient instance
        self.agents = [
            AIAbiturAgent(),
            KadrAIAgent(),
            UniNavAgent(),
            CareerNavigatorAgent(),
            UniRoomAgent()
        ]
        logger.info(f"AgentRouter initialized with {len(self.agents)} agents")

    def route_message(self, message: str, language: str = "ru", user_id: str = "anonymous") -> Dict[str, Any]:
        """Enhanced agent routing with ML-based intent classification"""
        try:
            # Import ML components
            from intent_classifier import intent_classifier
            from personalization_engine import personalization_engine
            from analytics_engine import analytics_engine
            
            # Get personalized agent recommendation
            recommendation_result = personalization_engine.get_agent_recommendation(
                user_id, message, [agent.agent_type for agent in self.agents]
            )
            recommended_agent, recommendation_confidence = recommendation_result if recommendation_result else (None, 0.0)
            
            # Use ML-based intent classification
            agent_scores = intent_classifier.classify_intent(message, language)
            
            # If we have a strong personal recommendation, boost its score
            if recommended_agent and recommended_agent in agent_scores:
                original_score = agent_scores[recommended_agent]
                boosted_score = min(1.0, original_score + recommendation_confidence * 0.2)
                agent_scores[recommended_agent] = boosted_score
                logger.info(f"Boosted {recommended_agent} score from {original_score:.3f} to {boosted_score:.3f} based on user preference")
            
            # Find best agent
            if agent_scores:
                best_agent_type = max(agent_scores, key=agent_scores.get)
                confidence = agent_scores[best_agent_type]
                
                # Find the agent instance
                best_agent = None
                for agent in self.agents:
                    if agent.agent_type == best_agent_type:
                        best_agent = agent
                        break
                
                if best_agent and confidence > 0.15:  # Minimum confidence threshold
                    logger.info(f"ML router selected {best_agent.name} with confidence {confidence:.3f}")
                    
                    # Process message with selected agent
                    result = best_agent.process_message(message, language, user_id)
                    
                    # Add routing information to result
                    result['routing_info'] = {
                        'ml_scores': agent_scores,
                        'selected_agent': best_agent_type,
                        'selection_confidence': confidence,
                        'recommended_agent': recommended_agent,
                        'recommendation_confidence': recommendation_confidence
                    }
                    
                    return result
            
            # Fallback to traditional routing if ML fails
            logger.warning("ML routing failed, falling back to traditional method")
            return self._traditional_routing(message, language, user_id)
            
        except Exception as e:
            logger.error(f"Error in enhanced routing: {e}")
            # Fallback to traditional routing
            return self._traditional_routing(message, language, user_id)
    
    def _traditional_routing(self, message: str, language: str = "ru", user_id: str = "anonymous") -> Dict[str, Any]:
        """Traditional keyword-based routing as fallback"""
        best_conf = 0
        best_agent = None
        
        for agent in self.agents:
            conf = agent.can_handle(message, language)
            if conf > best_conf:
                best_conf = conf
                best_agent = agent
        
        if best_agent:
            logger.info(f"Traditional router selected {best_agent.name} with confidence {best_conf:.3f}")
            result = best_agent.process_message(message, language, user_id)
            result['routing_info'] = {
                'method': 'traditional',
                'selected_agent': best_agent.agent_type,
                'selection_confidence': best_conf
            }
            return result
        else:
            # No agent can handle, return general error
            return {
                'response': "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰ÐµÐ³Ð¾ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚Ð° Ð´Ð»Ñ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°. ÐžÐ±Ñ€Ð°Ñ‚Ð¸Ñ‚ÐµÑÑŒ Ð² Ð¾Ð±Ñ‰ÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¾Ð½Ð½ÑƒÑŽ ÑÐ»ÑƒÐ¶Ð±Ñƒ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ¸Ñ‚ÐµÑ‚Ð°.",
                'confidence': 0.1,
                'agent_type': 'none',
                'agent_name': 'Router',
                'context_used': False,
                'context_confidence': 0.0,
                'cached': False,
                'routing_error': True
            }
    
    def provide_feedback(self, user_id: str, message: str, agent_type: str, 
                        user_rating: float, feedback_text: str = ""):
        """Provide feedback for learning improvement"""
        try:
            from intent_classifier import intent_classifier
            from personalization_engine import personalization_engine
            from analytics_engine import analytics_engine
            
            # Update intent classifier with feedback
            intent_classifier.learn_from_feedback(message, agent_type, user_rating)
            
            # Update personalization engine
            personalization_engine.add_user_feedback(user_id, user_rating, feedback_text)
            
            # Track in analytics
            analytics_engine.track_interaction({
                'user_id': user_id,
                'message': message,
                'agent_type': agent_type,
                'user_rating': user_rating,
                'feedback_text': feedback_text,
                'language': 'ru'  # Default, could be parameterized
            })
            
            logger.info(f"Processed feedback: user={user_id}, agent={agent_type}, rating={user_rating}")
            
        except Exception as e:
            logger.error(f"Error processing feedback: {e}")
    
    def get_routing_analytics(self) -> Dict[str, Any]:
        """Get analytics about routing performance"""
        try:
            from intent_classifier import intent_classifier
            from analytics_engine import analytics_engine
            
            # Get ML classifier stats
            ml_stats = intent_classifier.get_learning_stats()
            
            # Get overall performance metrics
            performance_metrics = analytics_engine.get_performance_metrics(time_window_hours=24)
            
            # Get agent usage distribution
            agent_usage = {}
            for agent in self.agents:
                agent_metrics = analytics_engine.get_performance_metrics(
                    agent_type=agent.agent_type, 
                    time_window_hours=24
                )
                agent_usage[agent.agent_type] = {
                    'name': agent.name,
                    'interactions': agent_metrics.get('total_interactions', 0),
                    'avg_confidence': agent_metrics.get('performance', {}).get('avg_confidence', 0)
                }
            
            return {
                'ml_classifier_stats': ml_stats,
                'overall_performance': performance_metrics,
                'agent_usage': agent_usage,
                'total_agents': len(self.agents)
            }
            
        except Exception as e:
            logger.error(f"Error getting routing analytics: {e}")
            return {'error': str(e)}

    def get_available_agents(self) -> List[Dict[str, str]]:
        return [{'type': a.agent_type, 'name': a.name, 'description': a.description} for a in self.agents]